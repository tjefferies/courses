{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Machine Learning Run Metadata Using sqlite\n",
    "\n",
    "Author: Travis Jefferies<br>\n",
    "Last Updated: 05/07/2019<br>\n",
    "\n",
    "This notebook walks through the creation of a flexible relational model that can be used to store metadata related to a given machine learning train/deployment run.  The relational model is then implemented in sqlite using a parallel ETL approach where data is stored in memory for on-demand processing needs downstream during training/deployment runs and archived on disk for reproducibility/audit trail purposes. Storing as much detail as possible about a given machine learning model run is necessary for model relevancy, metric tracking, and model assessment. Other pros/cons of this implementation technique are also explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "np.random.seed(0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.externals import joblib\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(':memory:')\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481909</td>\n",
       "      <td>1.736034</td>\n",
       "      <td>-0.744777</td>\n",
       "      <td>-0.444399</td>\n",
       "      <td>-0.243341</td>\n",
       "      <td>1.468105</td>\n",
       "      <td>0.335756</td>\n",
       "      <td>2.043661</td>\n",
       "      <td>-0.802371</td>\n",
       "      <td>2.562580</td>\n",
       "      <td>2.591761</td>\n",
       "      <td>-0.122900</td>\n",
       "      <td>-1.542755</td>\n",
       "      <td>-0.152473</td>\n",
       "      <td>1.436250</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328469</td>\n",
       "      <td>-0.182103</td>\n",
       "      <td>0.981706</td>\n",
       "      <td>1.426025</td>\n",
       "      <td>0.024267</td>\n",
       "      <td>-1.369246</td>\n",
       "      <td>-0.367076</td>\n",
       "      <td>-0.287884</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.681591</td>\n",
       "      <td>0.858579</td>\n",
       "      <td>1.175316</td>\n",
       "      <td>-1.926863</td>\n",
       "      <td>0.778596</td>\n",
       "      <td>0.169588</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.667993</td>\n",
       "      <td>-0.544896</td>\n",
       "      <td>-1.870499</td>\n",
       "      <td>-1.087367</td>\n",
       "      <td>3.878025</td>\n",
       "      <td>0.247470</td>\n",
       "      <td>0.731654</td>\n",
       "      <td>-0.467665</td>\n",
       "      <td>0.181174</td>\n",
       "      <td>-2.581402</td>\n",
       "      <td>1.850208</td>\n",
       "      <td>-0.707648</td>\n",
       "      <td>1.252330</td>\n",
       "      <td>0.213449</td>\n",
       "      <td>3.042264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.320857</td>\n",
       "      <td>-1.378812</td>\n",
       "      <td>-0.040409</td>\n",
       "      <td>2.540748</td>\n",
       "      <td>-3.109547</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>-0.644819</td>\n",
       "      <td>1.227046</td>\n",
       "      <td>1.773983</td>\n",
       "      <td>0.074522</td>\n",
       "      <td>-1.186576</td>\n",
       "      <td>0.357030</td>\n",
       "      <td>1.000647</td>\n",
       "      <td>1.527006</td>\n",
       "      <td>-2.049990</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.944246</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-1.067252</td>\n",
       "      <td>-0.680489</td>\n",
       "      <td>1.054587</td>\n",
       "      <td>-1.165969</td>\n",
       "      <td>1.134462</td>\n",
       "      <td>4.217619</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>4.040406</td>\n",
       "      <td>0.538467</td>\n",
       "      <td>1.125189</td>\n",
       "      <td>2.910772</td>\n",
       "      <td>-0.817434</td>\n",
       "      <td>-2.753014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.481909  1.736034 -0.744777 -0.444399 -0.243341  1.468105  0.335756   \n",
       "1  0.328469 -0.182103  0.981706  1.426025  0.024267 -1.369246 -0.367076   \n",
       "2 -0.667993 -0.544896 -1.870499 -1.087367  3.878025  0.247470  0.731654   \n",
       "3  0.320857 -1.378812 -0.040409  2.540748 -3.109547 -0.003694 -0.644819   \n",
       "4  1.944246  0.101500 -1.067252 -0.680489  1.054587 -1.165969  1.134462   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  2.043661 -0.802371  2.562580  2.591761 -0.122900 -1.542755 -0.152473   \n",
       "1 -0.287884  0.109971  0.681591  0.858579  1.175316 -1.926863  0.778596   \n",
       "2 -0.467665  0.181174 -2.581402  1.850208 -0.707648  1.252330  0.213449   \n",
       "3  1.227046  1.773983  0.074522 -1.186576  0.357030  1.000647  1.527006   \n",
       "4  4.217619  0.435200  4.040406  0.538467  1.125189  2.910772 -0.817434   \n",
       "\n",
       "         14  target  \n",
       "0  1.436250       3  \n",
       "1  0.169588      19  \n",
       "2  3.042264       0  \n",
       "3 -2.049990      15  \n",
       "4 -2.753014       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, target = make_classification(n_samples=1000, n_features=15, n_informative=6, n_classes=20)\n",
    "df = pd.concat([pd.DataFrame(features), pd.Series(target,name='target')], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), df['target'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store current time as `str`\n",
    "\n",
    "We'll use this later in a variety of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201905101901'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y%m%d%H%M\")\n",
    "now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and tune hyper parameters using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc untuned accuracy: 0.295\n",
      "{'max_depth': 20, 'max_features': 'auto', 'n_estimators': 40}\n",
      "tuned accuracy: 0.315\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X_train, y_train)\n",
    "train_untuned_accuracy = clf.score(X_test, y_test)\n",
    "print('rfc untuned accuracy: {}'.format(train_untuned_accuracy))\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [20, 40],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth': [10,20]\n",
    "}\n",
    "\n",
    "\n",
    "t = time.asctime( time.localtime(time.time()) )\n",
    "CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)\n",
    "CV_rfc.refit\n",
    "e = time.asctime( time.localtime(time.time()) )\n",
    "train_tuned_accuracy = CV_rfc.score(X_test, y_test)\n",
    "print('tuned accuracy: {}'.format(train_tuned_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SQLite` class\n",
    "\n",
    "The `SQLite` class is used to create the sqlite database and execute queries.<br>\n",
    "Under the hood, it uses `pandas` and `sqlite3` python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLite:\n",
    "\n",
    "    def __init__(self, db=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        if db:\n",
    "            assert isinstance(db, str)\n",
    "            assert db.split('.')[1] == 'db'\n",
    "        self.create_connection(db)\n",
    "    \n",
    "    \n",
    "    def create_connection(self, db=None):\n",
    "        \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "        try:\n",
    "            if db:\n",
    "                self.conn = sqlite3.connect(db)\n",
    "                print(sqlite3.version)\n",
    "            else:\n",
    "                self.conn = sqlite3.connect(':memory:')\n",
    "                print(sqlite3.version)\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "    \n",
    "    def close_conn(self):\n",
    "        self.conn.close()\n",
    "            \n",
    "def query_sqlite_db(conn, query):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()    \n",
    "        cur.execute(query)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "create_sql = \"\"\"CREATE TABLE Model(id INTEGER PRIMARY KEY, name TEXT, type TEXT, start_dt FLOAT, end_dt FLOAT)\"\"\"\n",
    "insert_sql = \"\"\"INSERT INTO Model VALUES({},'{}','{}','{}','{}')\"\"\".format(now, type(CV_rfc.estimator).__name__ ,str(type(CV_rfc.estimator))[8:-2],t,e)\n",
    "\n",
    "s = SQLite()\n",
    "query_sqlite_db(s.conn, create_sql)\n",
    "query_sqlite_db(s.conn, insert_sql)\n",
    "df = pd.read_sql_query('select * from Model',s.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>end_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201905101901</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>sklearn.ensemble.forest.RandomForestClassifier</td>\n",
       "      <td>Fri May 10 19:01:50 2019</td>\n",
       "      <td>Fri May 10 19:01:57 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                    name  \\\n",
       "0  201905101901  RandomForestClassifier   \n",
       "\n",
       "                                             type                  start_dt  \\\n",
       "0  sklearn.ensemble.forest.RandomForestClassifier  Fri May 10 19:01:50 2019   \n",
       "\n",
       "                     end_dt  \n",
       "0  Fri May 10 19:01:57 2019  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the concept to .pkl files\n",
    "\n",
    "Now let's extend the concept from above to include .pkl files generated during the machine learning lifecycle. We'll be using the `cv_results_` attribute of the `GridSearchCV` object to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# reference: https://stackoverflow.com/a/2340858\n",
    "\n",
    "pdata0 = pickle.dumps(CV_rfc.best_params_, pickle.HIGHEST_PROTOCOL)\n",
    "pdata1 = pickle.dumps(CV_rfc.cv_results_['params'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata2 = pickle.dumps(CV_rfc.cv_results_['mean_test_score'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata3 = pickle.dumps(CV_rfc.cv_results_['mean_train_score'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata4 = pickle.dumps(CV_rfc.cv_results_['mean_fit_time'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata5 = pickle.dumps(CV_rfc.cv_results_['mean_score_time'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata6 = pickle.dumps(CV_rfc.best_estimator_, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ModelGeneral_sql = \"\"\"CREATE TABLE ModelTrainCV(id INTEGER PRIMARY KEY, name TEXT, type TEXT, start_dt TEXT, end_dt TEXT, optimal_model_params BLOB, all_models_params BLOB, all_models_test_scores BLOB, all_models_train_scores BLOB, all_models_fit_time_secs BLOB, all_models_score_time_secs BLOB, optimal_model BLOB)\"\"\"\n",
    "curr = s.conn.cursor()\n",
    "curr.execute(create_ModelGeneral_sql)\n",
    "curr.execute(\"INSERT INTO ModelTrainCV VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\",(now, type(CV_rfc.estimator).__name__, str(type(CV_rfc.estimator))[8:-2], t, e, sqlite3.Binary(pdata0), sqlite3.Binary(pdata1), sqlite3.Binary(pdata2), sqlite3.Binary(pdata3), sqlite3.Binary(pdata4), sqlite3.Binary(pdata5), sqlite3.Binary(pdata6)))\n",
    "df = pd.read_sql_query('select * from ModelTrainCV',s.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>end_dt</th>\n",
       "      <th>optimal_model_params</th>\n",
       "      <th>all_models_params</th>\n",
       "      <th>all_models_test_scores</th>\n",
       "      <th>all_models_train_scores</th>\n",
       "      <th>all_models_fit_time_secs</th>\n",
       "      <th>all_models_score_time_secs</th>\n",
       "      <th>optimal_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201905101901</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>sklearn.ensemble.forest.RandomForestClassifier</td>\n",
       "      <td>Fri May 10 19:01:50 2019</td>\n",
       "      <td>Fri May 10 19:01:57 2019</td>\n",
       "      <td>b'\\x80\\x04\\x95:\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x...</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xb3\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x04\\x95\\x1f;\\x02\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                    name  \\\n",
       "0  201905101901  RandomForestClassifier   \n",
       "\n",
       "                                             type                  start_dt  \\\n",
       "0  sklearn.ensemble.forest.RandomForestClassifier  Fri May 10 19:01:50 2019   \n",
       "\n",
       "                     end_dt  \\\n",
       "0  Fri May 10 19:01:57 2019   \n",
       "\n",
       "                                optimal_model_params  \\\n",
       "0  b'\\x80\\x04\\x95:\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x...   \n",
       "\n",
       "                                   all_models_params  \\\n",
       "0  b'\\x80\\x04\\x95\\xb3\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                              all_models_test_scores  \\\n",
       "0  b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                             all_models_train_scores  \\\n",
       "0  b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                            all_models_fit_time_secs  \\\n",
       "0  b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                          all_models_score_time_secs  \\\n",
       "0  b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                                       optimal_model  \n",
       "0  b'\\x80\\x04\\x95\\x1f;\\x02\\x00\\x00\\x00\\x00\\x00\\x8...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.loads(df['optimal_model'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "assert np.allclose(model.predict(X_test), CV_rfc.predict(X_test))\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write in memory database to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.conn.commit()\n",
    "\n",
    "# write database to disk\n",
    "\n",
    "c2 = sqlite3.connect('mydb.db')\n",
    "with c2:\n",
    "    for line in s.conn.iterdump():\n",
    "        if line not in ('BEGIN;', 'COMMIT;'): # let python handle the transactions\n",
    "            c2.execute(line)\n",
    "c2.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close_conn()\n",
    "c2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip and remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_database(zip_file_path, sqlite_db_file_path):\n",
    "    \"\"\"Function to dump sqlite3 database into zipped file\n",
    "    see: http://bit.ly/IAUmKc\n",
    "    python 2.6+ only\n",
    "    connection: sqlite3 database connection\n",
    "    dumpfile: the name of the zipfile to store the sql_file info \n",
    "              [remember to add a .zip extension]\n",
    "    sql_file: The name of the sql file to dump the database info into\n",
    "              [remember to add a .sql extension]\n",
    "    \"\"\"\n",
    "    \n",
    "    zf = zipfile.ZipFile(zip_file_path, mode='w', compression = zipfile.ZIP_DEFLATED)\n",
    "\n",
    "    # Create a zip file and write add the dump into it as a new file\n",
    "    zf.write(os.getcwd()+'\\\\'+sqlite_db_file_path)\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_database('test2.zip', 'mydb.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(os.getcwd()+'\\\\'+'mydb.db'):\n",
    "    os.remove(os.getcwd()+'\\\\'+'mydb.db')\n",
    "else:    ## Show an error ##\n",
    "    print(\"Error: %s file not found\" % os.getcwd()+'\\\\'+'mydb.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
