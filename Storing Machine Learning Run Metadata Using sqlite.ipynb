{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Machine Learning Run Metadata Using sqlite\n",
    "\n",
    "Author: Travis Jefferies<br>\n",
    "Last Updated: 05/07/2019<br>\n",
    "\n",
    "This notebook walks through the creation of a flexible relational model that can be used to store metadata related to a given machine learning train/deployment run.  The relational model is then implemented in sqlite using a parallel ETL approach where data is stored in memory for on-demand processing needs downstream during training/deployment runs and archived on disk for reproducibility/audit trail purposes. Storing as much detail as possible about a given machine learning model run is necessary for model relevancy, metric tracking, and model assessment. Other pros/cons of this implementation technique are also explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "np.random.seed(0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(':memory:')\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = make_classification(n_samples=1000, n_features=15, n_informative=6, n_classes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store current time as `str`\n",
    "\n",
    "We'll use this later in a variety of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201905072022'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y%m%d%H%M\")\n",
    "now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and tune hyper parameters using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc untuned accuracy: 0.994\n",
      "{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 40}\n",
      "tuned accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(features, target)\n",
    "train_untuned_accuracy = clf.score(features, target)\n",
    "print('rfc untuned accuracy: {}'.format(train_untuned_accuracy))\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [20, 40],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth': [10,20]\n",
    "}\n",
    "\n",
    "\n",
    "t = time.asctime( time.localtime(time.time()) )\n",
    "CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10)\n",
    "CV_rfc.fit(features, target)\n",
    "print(CV_rfc.best_params_)\n",
    "CV_rfc.refit\n",
    "e = time.asctime( time.localtime(time.time()) )\n",
    "train_tuned_accuracy = CV_rfc.score(features, target)\n",
    "print('tuned accuracy: {}'.format(train_tuned_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SQLite` class\n",
    "\n",
    "The `SQLite` class is used to create the sqlite database and execute queries.<br>\n",
    "Under the hood, it uses `pandas` and `sqlite3` python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLite:\n",
    "\n",
    "    def __init__(self, db=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        if db:\n",
    "            assert isinstance(db, str)\n",
    "            assert db.split('.')[1] == 'db'\n",
    "        self.create_connection(db)\n",
    "    \n",
    "    \n",
    "    def create_connection(self, db=None):\n",
    "        \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "        try:\n",
    "            if db:\n",
    "                self.conn = sqlite3.connect(db)\n",
    "                print(sqlite3.version)\n",
    "            else:\n",
    "                self.conn = sqlite3.connect(':memory:')\n",
    "                print(sqlite3.version)\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "    \n",
    "    def close_conn(self):\n",
    "        self.conn.close()\n",
    "            \n",
    "def query_sqlite_db(conn, query):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()    \n",
    "        cur.execute(query)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "create_sql = \"\"\"CREATE TABLE Model(id INTEGER PRIMARY KEY, name TEXT, type TEXT, start_dt FLOAT, end_dt FLOAT)\"\"\"\n",
    "insert_sql = \"\"\"INSERT INTO Model VALUES({},'{}','{}','{}','{}')\"\"\".format(now, type(CV_rfc.estimator).__name__ ,str(type(CV_rfc.estimator))[8:-2],t,e)\n",
    "\n",
    "s = SQLite()\n",
    "query_sqlite_db(s.conn, create_sql)\n",
    "query_sqlite_db(s.conn, insert_sql)\n",
    "df = pd.read_sql_query('select * from Model',s.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>end_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201905072022</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>sklearn.ensemble.forest.RandomForestClassifier</td>\n",
       "      <td>Tue May  7 20:23:20 2019</td>\n",
       "      <td>Tue May  7 20:23:30 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                    name  \\\n",
       "0  201905072022  RandomForestClassifier   \n",
       "\n",
       "                                             type                  start_dt  \\\n",
       "0  sklearn.ensemble.forest.RandomForestClassifier  Tue May  7 20:23:20 2019   \n",
       "\n",
       "                     end_dt  \n",
       "0  Tue May  7 20:23:30 2019  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending the concept to .pkl files\n",
    "\n",
    "Now let's extend the concept from above to include .pkl files generated during the machine learning lifecycle. We'll be using the `cv_results_` attribute of the `GridSearchCV` object to illustrate."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CV_rfc.cv_results_\n",
    "\n",
    "{'mean_fit_time': array([0.11865807, 0.14691019, 0.07582609, 0.1420269 , 0.0953358 ,\n",
    "        0.19926937, 0.09385451, 0.1835196 ]),\n",
    " 'std_fit_time': array([0.05083234, 0.02310043, 0.0069841 , 0.02047634, 0.01849434,\n",
    "        0.03950515, 0.019211  , 0.03255829]),\n",
    " 'mean_score_time': array([0.01373442, 0.02408957, 0.01274014, 0.02250703, 0.01432649,\n",
    "        0.02486626, 0.01278464, 0.02503578]),\n",
    " 'std_score_time': array([0.00038935, 0.00303121, 0.00037838, 0.00150065, 0.00187225,\n",
    "        0.00229845, 0.00087957, 0.00150615]),\n",
    " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 20, 20, 20, 20],\n",
    "              mask=[False, False, False, False, False, False, False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'param_max_features': masked_array(data=['auto', 'auto', 'log2', 'log2', 'auto', 'auto', 'log2',\n",
    "                    'log2'],\n",
    "              mask=[False, False, False, False, False, False, False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'param_n_estimators': masked_array(data=[20, 40, 20, 40, 20, 40, 20, 40],\n",
    "              mask=[False, False, False, False, False, False, False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'params': [{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 20},\n",
    "  {'max_depth': 10, 'max_features': 'auto', 'n_estimators': 40},\n",
    "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 20},\n",
    "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 40},\n",
    "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 20},\n",
    "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 40},\n",
    "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 20},\n",
    "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 40}],\n",
    " 'split0_test_score': array([0.60997732, 0.63265306, 0.60997732, 0.63265306, 0.61451247,\n",
    "        0.63265306, 0.61451247, 0.63265306]),\n",
    " 'split1_test_score': array([0.73134328, 0.73731343, 0.73134328, 0.73731343, 0.74925373,\n",
    "        0.77313433, 0.74925373, 0.77313433]),\n",
    " 'split2_test_score': array([0.69649805, 0.72762646, 0.69649805, 0.72762646, 0.73540856,\n",
    "        0.74708171, 0.73540856, 0.74708171]),\n",
    " 'mean_test_score': array([0.67086157, 0.69022265, 0.67086157, 0.69022265, 0.68828654,\n",
    "        0.70667957, 0.68828654, 0.70667957]),\n",
    " 'std_test_score': array([0.05415093, 0.04982077, 0.05415093, 0.04982077, 0.06388557,\n",
    "        0.06463536, 0.06388557, 0.06463536]),\n",
    " 'rank_test_score': array([7, 3, 7, 3, 5, 1, 5, 1], dtype=int32),\n",
    " 'split0_train_score': array([0.94087838, 0.95945946, 0.94087838, 0.95945946, 0.99831081,\n",
    "        0.99831081, 0.99831081, 0.99831081]),\n",
    " 'split1_train_score': array([0.89684814, 0.94269341, 0.89684814, 0.94269341, 0.99426934,\n",
    "        1.        , 0.99426934, 1.        ]),\n",
    " 'split2_train_score': array([0.89561856, 0.92912371, 0.89561856, 0.92912371, 0.99871134,\n",
    "        0.99871134, 0.99871134, 0.99871134]),\n",
    " 'mean_train_score': array([0.91111502, 0.94375886, 0.91111502, 0.94375886, 0.99709716,\n",
    "        0.99900738, 0.99709716, 0.99900738]),\n",
    " 'std_train_score': array([0.02105186, 0.01240741, 0.02105186, 0.01240741, 0.00200625,\n",
    "        0.00072068, 0.00200625, 0.00072068])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# reference: https://stackoverflow.com/a/2340858\n",
    "\n",
    "pdata0 = pickle.dumps(CV_rfc.best_params_, pickle.HIGHEST_PROTOCOL)\n",
    "pdata1 = pickle.dumps(CV_rfc.cv_results_['params'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata2 = pickle.dumps(CV_rfc.cv_results_['mean_test_score'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata3 = pickle.dumps(CV_rfc.cv_results_['mean_train_score'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata4 = pickle.dumps(CV_rfc.cv_results_['mean_fit_time'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata5 = pickle.dumps(CV_rfc.cv_results_['mean_score_time'], pickle.HIGHEST_PROTOCOL)\n",
    "pdata6 = pickle.dumps(CV_rfc.best_estimator_, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ModelGeneral_sql = \"\"\"CREATE TABLE ModelTrainCV(id INTEGER PRIMARY KEY, name TEXT, type TEXT, start_dt TEXT, end_dt TEXT, optimal_model_params BLOB, all_models_params BLOB, all_models_test_scores BLOB, all_models_train_scores BLOB, all_models_fit_time_secs BLOB, all_models_score_time_secs BLOB, optimal_model BLOB)\"\"\"\n",
    "curr = s.conn.cursor()\n",
    "curr.execute(create_ModelGeneral_sql)\n",
    "curr.execute(\"INSERT INTO ModelTrainCV VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\",(now, type(CV_rfc.estimator).__name__, str(type(CV_rfc.estimator))[8:-2], t, e, sqlite3.Binary(pdata0), sqlite3.Binary(pdata1), sqlite3.Binary(pdata2), sqlite3.Binary(pdata3), sqlite3.Binary(pdata4), sqlite3.Binary(pdata5), sqlite3.Binary(pdata6)))\n",
    "df = pd.read_sql_query('select id, all_models_score_time_secs from ModelTrainCV',s.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>all_models_score_time_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201905072022</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         all_models_score_time_secs\n",
       "0  201905072022  b'\\x80\\x04\\x95\\xca\\x00\\x00\\x00\\x00\\x00\\x00\\x00..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0025784 , 0.00430191, 0.00259876, 0.00440335, 0.00276504,\n",
       "       0.00532231, 0.0028295 , 0.00483508])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(df['all_models_score_time_secs'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write in memory database to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.conn.commit()\n",
    "\n",
    "# write database to disk\n",
    "\n",
    "c2 = sqlite3.connect('mydb.db')\n",
    "with c2:\n",
    "    for line in s.conn.iterdump():\n",
    "        if line not in ('BEGIN;', 'COMMIT;'): # let python handle the transactions\n",
    "            c2.execute(line)\n",
    "c2.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close_conn()\n",
    "c2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
